"""
SymbioMark
ВОПРОС 2 ИЗ 11
Внимание!
При ответе на данный вопрос запрещается использовать сторонние источники и подсказки третьих лиц!
Пожалуйста, не покидайте данную вкладку браузера, не пользуйтесь консолью и посторонней помощью!
Попытки списывания и использования посторонней помощи будут учтены при проверке Ваших ответов.
Вопрос
Представьте, что у Вас есть сайт, состоящий примерно из 300-400 страниц. Напишите на Python скрипт, который будет анализировать сайт и выводить перечень ссылок, находящихся на страницах сайта и ведущих на несуществующие страницы. На входе программы - адрес сайта.
Поскольку в данной задаче может быть множество деталей и "подводных камней", нужно написать первую версию скрипта, которая, на Ваш взгляд, должна работать, а также перечень возможных улучшений, которые можно было бы внести в будущем.
"""

import re
import requests
from urllib.parse import urlparse


def check(url):
    # получаем текст страницы
    page = requests.get(url)
    # находим все ссылки
    urls = re.findall(r'href=[\'"]?([^\'" >]+)', page.text)
    # приводим ссылки к нормальному виду
    urls = [f'http:{u}' if u[0:2] == '//' else f'{url}{u}' if u[0] == '/' or u[0] == '#' else u for u in urls]
    # цикл по всем ссылкам
    for _url in urls:
        u = urlparse(_url)
        u1 = urlparse(url)
        # если ссылка принадлежит нашему домену, рекурсивно вызываем функцию
        if u.netloc == u1.netloc:
            check(_url)
        # проверяем текущую ссылку
        try:
            response = requests.get(_url)
            if response.status_code != 200:
                print(f'ссылка {url} ведёт на несуществующую страницу!', end='\n')
        except requests.exceptions.ConnectionError:
            print(f'домен ссылки {url} не доступен', end='\n')
    print(f'На странице {url}, все ссылки действительны')


# старт-бот
print("Введите url:")
check(input())
